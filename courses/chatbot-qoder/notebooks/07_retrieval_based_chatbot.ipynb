{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07: Retrieval-Based Chatbot\n",
    "\n",
    "**Duration:** 3-4 hours | **Difficulty:** Intermediate\n",
    "\n",
    "## Learning Objectives\n",
    "- Information retrieval fundamentals\n",
    "- Embedding spaces and similarity metrics\n",
    "- Response ranking systems\n",
    "- FAQ chatbot implementation\n",
    "\n",
    "## Table of Contents\n",
    "1. [Retrieval-Based Systems](#1-introduction)\n",
    "2. [Text Embeddings](#2-embeddings)\n",
    "3. [Similarity Computation](#3-similarity)\n",
    "4. [Response Ranking](#4-ranking)\n",
    "5. [FAQ Chatbot](#5-chatbot)\n",
    "6. [Practical Exercise](#6-exercise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "\n",
    "# Import utilities\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from utils.text_utils import TextPreprocessor\n",
    "from utils.model_helpers import get_device\n",
    "\n",
    "device = get_device(\"auto\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Retrieval-Based Systems {#1-introduction}\n",
    "\n",
    "**Retrieval-based chatbots** select responses from a predefined set rather than generating new text. They excel at:\n",
    "- Consistent, reliable responses\n",
    "- Domain-specific knowledge (FAQ, customer service)\n",
    "- Lower computational requirements\n",
    "\n",
    "### Architecture:\n",
    "1. **Knowledge Base**: Collection of question-answer pairs\n",
    "2. **Retriever**: Finds relevant responses\n",
    "3. **Ranker**: Scores and ranks candidates\n",
    "4. **Selector**: Chooses final response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load FAQ knowledge base\n",
    "with open('../data/conversations/faq_knowledge.json', 'r') as f:\n",
    "    faq_data = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(faq_data)} FAQ entries\")\n",
    "print(\"Sample entry:\")\n",
    "print(f\"Q: {faq_data[0]['question']}\")\n",
    "print(f\"A: {faq_data[0]['answer'][:100]}...\")\n",
    "print(f\"Category: {faq_data[0]['category']}\")\n",
    "print(f\"Keywords: {faq_data[0]['keywords'][:3]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Text Embeddings {#2-embeddings}\n",
    "\n",
    "Convert text to numerical vectors that capture semantic meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextEmbedder:\n",
    "    \"\"\"Text embedding using TF-IDF and simple neural embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, method='tfidf'):\n",
    "        self.method = method\n",
    "        self.preprocessor = TextPreprocessor()\n",
    "        \n",
    "        if method == 'tfidf':\n",
    "            self.vectorizer = TfidfVectorizer(\n",
    "                max_features=5000,\n",
    "                stop_words='english',\n",
    "                ngram_range=(1, 2),\n",
    "                lowercase=True\n",
    "            )\n",
    "    \n",
    "    def fit(self, texts: List[str]):\n",
    "        \"\"\"Fit embedder on text corpus.\"\"\"\n",
    "        if self.method == 'tfidf':\n",
    "            processed_texts = [self.preprocessor.preprocess(text) for text in texts]\n",
    "            self.vectorizer.fit(processed_texts)\n",
    "        \n",
    "        print(f\"Fitted {self.method} embedder on {len(texts)} texts\")\n",
    "    \n",
    "    def embed(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"Convert texts to embeddings.\"\"\"\n",
    "        if self.method == 'tfidf':\n",
    "            processed_texts = [self.preprocessor.preprocess(text) for text in texts]\n",
    "            return self.vectorizer.transform(processed_texts).toarray()\n",
    "    \n",
    "    def embed_single(self, text: str) -> np.ndarray:\n",
    "        \"\"\"Embed single text.\"\"\"\n",
    "        return self.embed([text])[0]\n",
    "\n",
    "# Create embedder and fit on FAQ data\n",
    "embedder = TextEmbedder('tfidf')\n",
    "\n",
    "# Prepare training texts (questions + answers)\n",
    "training_texts = []\n",
    "for entry in faq_data:\n",
    "    training_texts.append(entry['question'])\n",
    "    training_texts.append(entry['answer'])\n",
    "\n",
    "embedder.fit(training_texts)\n",
    "\n",
    "# Embed all questions\n",
    "questions = [entry['question'] for entry in faq_data]\n",
    "question_embeddings = embedder.embed(questions)\n",
    "\n",
    "print(f\"Question embeddings shape: {question_embeddings.shape}\")\n",
    "print(f\"Sample embedding (first 10 dims): {question_embeddings[0][:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Similarity Computation {#3-similarity}\n",
    "\n",
    "Measure semantic similarity between query and knowledge base entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityMatcher:\n",
    "    \"\"\"Compute similarity between queries and knowledge base.\"\"\"\n",
    "    \n",
    "    def __init__(self, embedder: TextEmbedder, kb_embeddings: np.ndarray):\n",
    "        self.embedder = embedder\n",
    "        self.kb_embeddings = kb_embeddings\n",
    "    \n",
    "    def find_similar(self, query: str, top_k: int = 5) -> List[Tuple[int, float]]:\n",
    "        \"\"\"Find most similar entries to query.\"\"\"\n",
    "        # Embed query\n",
    "        query_embedding = self.embedder.embed_single(query).reshape(1, -1)\n",
    "        \n",
    "        # Compute similarities\n",
    "        similarities = cosine_similarity(query_embedding, self.kb_embeddings)[0]\n",
    "        \n",
    "        # Get top-k indices and scores\n",
    "        top_indices = np.argsort(similarities)[-top_k:][::-1]\n",
    "        top_scores = similarities[top_indices]\n",
    "        \n",
    "        return list(zip(top_indices, top_scores))\n",
    "    \n",
    "    def compute_similarity_matrix(self, queries: List[str]) -> np.ndarray:\n",
    "        \"\"\"Compute similarity matrix for multiple queries.\"\"\"\n",
    "        query_embeddings = self.embedder.embed(queries)\n",
    "        return cosine_similarity(query_embeddings, self.kb_embeddings)\n",
    "\n",
    "# Create similarity matcher\n",
    "matcher = SimilarityMatcher(embedder, question_embeddings)\n",
    "\n",
    "# Test similarity matching\n",
    "test_queries = [\n",
    "    \"What is machine learning?\",\n",
    "    \"How do neural networks work?\",\n",
    "    \"What is deep learning?\",\n",
    "    \"How to start programming?\"\n",
    "]\n",
    "\n",
    "print(\"Similarity matching results:\")\n",
    "for query in test_queries:\n",
    "    similar_entries = matcher.find_similar(query, top_k=3)\n",
    "    print(f\"\\nQuery: '{query}'\")\n",
    "    \n",
    "    for idx, score in similar_entries:\n",
    "        question = faq_data[idx]['question']\n",
    "        print(f\"  Score: {score:.3f} - {question}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Response Ranking {#4-ranking}\n",
    "\n",
    "Rank candidate responses using multiple features and scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseRanker:\n",
    "    \"\"\"Rank responses using multiple features.\"\"\"\n",
    "    \n",
    "    def __init__(self, faq_data: List[Dict], matcher: SimilarityMatcher):\n",
    "        self.faq_data = faq_data\n",
    "        self.matcher = matcher\n",
    "    \n",
    "    def keyword_match_score(self, query: str, entry: Dict) -> float:\n",
    "        \"\"\"Score based on keyword matching.\"\"\"\n",
    "        query_words = set(query.lower().split())\n",
    "        entry_keywords = set([kw.lower() for kw in entry['keywords']])\n",
    "        \n",
    "        # Jaccard similarity\n",
    "        intersection = len(query_words & entry_keywords)\n",
    "        union = len(query_words | entry_keywords)\n",
    "        \n",
    "        return intersection / union if union > 0 else 0.0\n",
    "    \n",
    "    def confidence_score(self, entry: Dict) -> float:\n",
    "        \"\"\"Use entry's confidence score.\"\"\"\n",
    "        return entry.get('confidence', 0.5)\n",
    "    \n",
    "    def category_relevance(self, query: str, entry: Dict) -> float:\n",
    "        \"\"\"Score based on category relevance.\"\"\"\n",
    "        # Simple category matching\n",
    "        category_keywords = {\n",
    "            'AI/ML Basics': ['ai', 'ml', 'machine', 'learning', 'artificial', 'intelligence'],\n",
    "            'Deep Learning': ['deep', 'neural', 'network', 'layers'],\n",
    "            'Programming': ['code', 'programming', 'python', 'language'],\n",
    "            'NLP': ['nlp', 'language', 'text', 'processing'],\n",
    "            'Chatbots': ['chatbot', 'conversation', 'dialogue']\n",
    "        }\n",
    "        \n",
    "        query_lower = query.lower()\n",
    "        category = entry['category']\n",
    "        \n",
    "        if category in category_keywords:\n",
    "            keywords = category_keywords[category]\n",
    "            matches = sum(1 for kw in keywords if kw in query_lower)\n",
    "            return matches / len(keywords)\n",
    "        \n",
    "        return 0.0\n",
    "    \n",
    "    def rank_responses(self, query: str, top_k: int = 5) -> List[Tuple[Dict, float]]:\n",
    "        \"\"\"Rank responses using combined scoring.\"\"\"\n",
    "        # Get similar entries\n",
    "        similar_entries = self.matcher.find_similar(query, top_k=min(top_k * 2, len(self.faq_data)))\n",
    "        \n",
    "        ranked_responses = []\n",
    "        \n",
    "        for idx, similarity_score in similar_entries:\n",
    "            entry = self.faq_data[idx]\n",
    "            \n",
    "            # Compute individual scores\n",
    "            keyword_score = self.keyword_match_score(query, entry)\n",
    "            confidence = self.confidence_score(entry)\n",
    "            category_score = self.category_relevance(query, entry)\n",
    "            \n",
    "            # Combined score (weighted)\n",
    "            final_score = (\n",
    "                0.5 * similarity_score +\n",
    "                0.2 * keyword_score +\n",
    "                0.2 * confidence +\n",
    "                0.1 * category_score\n",
    "            )\n",
    "            \n",
    "            ranked_responses.append((entry, final_score))\n",
    "        \n",
    "        # Sort by final score\n",
    "        ranked_responses.sort(key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return ranked_responses[:top_k]\n",
    "\n",
    "# Create ranker\n",
    "ranker = ResponseRanker(faq_data, matcher)\n",
    "\n",
    "# Test ranking\n",
    "print(\"Response ranking results:\")\n",
    "test_query = \"How do I learn machine learning?\"\n",
    "ranked_responses = ranker.rank_responses(test_query, top_k=3)\n",
    "\n",
    "print(f\"\\nQuery: '{test_query}'\")\n",
    "for i, (entry, score) in enumerate(ranked_responses, 1):\n",
    "    print(f\"\\n{i}. Score: {score:.3f}\")\n",
    "    print(f\"   Q: {entry['question']}\")\n",
    "    print(f\"   A: {entry['answer'][:80]}...\")\n",
    "    print(f\"   Category: {entry['category']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. FAQ Chatbot Implementation {#5-chatbot}\n",
    "\n",
    "Complete retrieval-based chatbot for FAQ responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalChatbot:\n",
    "    \"\"\"Complete retrieval-based FAQ chatbot.\"\"\"\n",
    "    \n",
    "    def __init__(self, faq_data: List[Dict], confidence_threshold: float = 0.3):\n",
    "        self.faq_data = faq_data\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        \n",
    "        # Initialize components\n",
    "        self.embedder = TextEmbedder('tfidf')\n",
    "        self._build_knowledge_base()\n",
    "        \n",
    "        self.matcher = SimilarityMatcher(self.embedder, self.question_embeddings)\n",
    "        self.ranker = ResponseRanker(faq_data, self.matcher)\n",
    "        \n",
    "        # Conversation context\n",
    "        self.conversation_history = []\n",
    "        \n",
    "    def _build_knowledge_base(self):\n",
    "        \"\"\"Build and index knowledge base.\"\"\"\n",
    "        # Prepare training texts\n",
    "        training_texts = []\n",
    "        for entry in self.faq_data:\n",
    "            training_texts.append(entry['question'])\n",
    "            training_texts.append(entry['answer'])\n",
    "        \n",
    "        # Fit embedder\n",
    "        self.embedder.fit(training_texts)\n",
    "        \n",
    "        # Embed questions\n",
    "        questions = [entry['question'] for entry in self.faq_data]\n",
    "        self.question_embeddings = self.embedder.embed(questions)\n",
    "        \n",
    "        print(f\"Knowledge base built with {len(self.faq_data)} entries\")\n",
    "    \n",
    "    def respond(self, user_input: str) -> Dict:\n",
    "        \"\"\"Generate response to user input.\"\"\"\n",
    "        # Add to conversation history\n",
    "        self.conversation_history.append({'role': 'user', 'content': user_input})\n",
    "        \n",
    "        # Rank responses\n",
    "        ranked_responses = self.ranker.rank_responses(user_input, top_k=1)\n",
    "        \n",
    "        if not ranked_responses:\n",
    "            response = {\n",
    "                'answer': \"I'm sorry, I don't have information about that topic.\",\n",
    "                'confidence': 0.0,\n",
    "                'source': None\n",
    "            }\n",
    "        else:\n",
    "            best_entry, score = ranked_responses[0]\n",
    "            \n",
    "            if score >= self.confidence_threshold:\n",
    "                response = {\n",
    "                    'answer': best_entry['answer'],\n",
    "                    'confidence': score,\n",
    "                    'source': best_entry,\n",
    "                    'category': best_entry['category']\n",
    "                }\n",
    "            else:\n",
    "                response = {\n",
    "                    'answer': f\"I found some information, but I'm not very confident. {best_entry['answer']}\",\n",
    "                    'confidence': score,\n",
    "                    'source': best_entry,\n",
    "                    'category': best_entry['category']\n",
    "                }\n",
    "        \n",
    "        # Add to conversation history\n",
    "        self.conversation_history.append({'role': 'assistant', 'content': response['answer']})\n",
    "        \n",
    "        return response\n",
    "    \n",
    "    def get_conversation_history(self) -> List[Dict]:\n",
    "        \"\"\"Get conversation history.\"\"\"\n",
    "        return self.conversation_history\n",
    "    \n",
    "    def reset_conversation(self):\n",
    "        \"\"\"Reset conversation history.\"\"\"\n",
    "        self.conversation_history = []\n",
    "\n",
    "# Create chatbot\n",
    "chatbot = RetrievalChatbot(faq_data, confidence_threshold=0.25)\n",
    "\n",
    "# Interactive demo\n",
    "print(\"=== FAQ Chatbot Demo ===\")\n",
    "print(\"Ask questions about AI, ML, programming, etc.\")\n",
    "print(\"Type 'quit' to exit\\n\")\n",
    "\n",
    "# Demo queries\n",
    "demo_queries = [\n",
    "    \"What is machine learning?\",\n",
    "    \"How do neural networks work?\",\n",
    "    \"What programming language should I learn?\",\n",
    "    \"How do I start with deep learning?\",\n",
    "    \"What is the difference between AI and ML?\"\n",
    "]\n",
    "\n",
    "for query in demo_queries:\n",
    "    print(f\"User: {query}\")\n",
    "    response = chatbot.respond(query)\n",
    "    print(f\"Bot: {response['answer']}\")\n",
    "    print(f\"Confidence: {response['confidence']:.3f}\")\n",
    "    if response.get('category'):\n",
    "        print(f\"Category: {response['category']}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nConversation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Practical Exercise {#6-exercise}\n",
    "\n",
    "**Exercise**: Enhance the retrieval-based chatbot\n",
    "\n",
    "### Tasks:\n",
    "1. Add semantic embeddings (Word2Vec, BERT)\n",
    "2. Implement context-aware retrieval\n",
    "3. Add response filtering and safety checks\n",
    "4. Create evaluation metrics (precision@k, MRR)\n",
    "\n",
    "### Extensions:\n",
    "- Multi-turn conversation support\n",
    "- Hybrid retrieval + generation\n",
    "- Domain adaptation techniques\n",
    "- Real-time learning from user feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Evaluation metrics\n",
    "def evaluate_retrieval(chatbot, test_queries, expected_categories):\n",
    "    \"\"\"Evaluate retrieval performance.\"\"\"\n",
    "    correct_category = 0\n",
    "    high_confidence = 0\n",
    "    \n",
    "    for query, expected_cat in zip(test_queries, expected_categories):\n",
    "        response = chatbot.respond(query)\n",
    "        \n",
    "        if response.get('category') == expected_cat:\n",
    "            correct_category += 1\n",
    "        \n",
    "        if response['confidence'] >= 0.5:\n",
    "            high_confidence += 1\n",
    "    \n",
    "    accuracy = correct_category / len(test_queries)\n",
    "    confidence_rate = high_confidence / len(test_queries)\n",
    "    \n",
    "    return {\n",
    "        'category_accuracy': accuracy,\n",
    "        'high_confidence_rate': confidence_rate,\n",
    "        'total_queries': len(test_queries)\n",
    "    }\n",
    "\n",
    "# Test evaluation\n",
    "test_queries = [\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"How do I code in Python?\",\n",
    "    \"What are transformers?\"\n",
    "]\n",
    "expected_cats = ['AI/ML Basics', 'Programming', 'Deep Learning']\n",
    "\n",
    "chatbot.reset_conversation()\n",
    "results = evaluate_retrieval(chatbot, test_queries, expected_cats)\n",
    "print(f\"\\nEvaluation Results:\")\n",
    "print(f\"Category Accuracy: {results['category_accuracy']:.2f}\")\n",
    "print(f\"High Confidence Rate: {results['high_confidence_rate']:.2f}\")\n",
    "\n",
    "print(\"\\n=== Retrieval-Based Chatbot Complete ===\")\n",
    "print(\"Key Concepts Learned:\")\n",
    "print(\"• Text embeddings and similarity matching\")\n",
    "print(\"• Multi-feature response ranking\")\n",
    "print(\"• Knowledge base indexing\")\n",
    "print(\"• Confidence-based response selection\")\n",
    "print(\"• Retrieval system evaluation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}