{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - PyTorch Fundamentals for Chatbot Development\n",
    "\n",
    "**Duration:** 1-2 hours | **Difficulty:** Beginner\n",
    "\n",
    "## ðŸŽ¯ Learning Objectives\n",
    "- Understand tensor creation, manipulation, and operations\n",
    "- Learn automatic differentiation with PyTorch's autograd\n",
    "- Implement basic gradient descent\n",
    "- Build a simple linear regression model\n",
    "\n",
    "## ðŸ“š Contents\n",
    "1. Tensors and Operations\n",
    "2. Automatic Differentiation\n",
    "3. Device Management\n",
    "4. Building Models\n",
    "5. Linear Regression Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "torch.manual_seed(42)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Tensors\n",
    "\n",
    "Tensors are the fundamental data structure in PyTorch. Think of them as multi-dimensional arrays that can run on GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar: 3.140000104904175, shape: torch.Size([])\n",
      "Vector: tensor([1, 2, 3, 4, 5]), shape: torch.Size([5])\n",
      "Matrix:\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "Shape: torch.Size([2, 2])\n",
      "\n",
      "Zeros:\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "Random:\n",
      "tensor([[ 0.3367,  0.1288,  0.2345],\n",
      "        [ 0.2303, -1.1229, -0.1863]])\n",
      "Range: tensor([0, 2, 4, 6, 8])\n"
     ]
    }
   ],
   "source": [
    "# Creating tensors\n",
    "scalar = torch.tensor(3.14)\n",
    "vector = torch.tensor([1, 2, 3, 4, 5])\n",
    "matrix = torch.tensor([[1, 2], [3, 4]])\n",
    "\n",
    "print(f\"Scalar: {scalar}, shape: {scalar.shape}\")\n",
    "print(f\"Vector: {vector}, shape: {vector.shape}\")\n",
    "print(f\"Matrix:\\n{matrix}\\nShape: {matrix.shape}\")\n",
    "\n",
    "# Common tensor creation functions\n",
    "zeros = torch.zeros(2, 3)\n",
    "random = torch.randn(2, 3)  # Normal distribution\n",
    "range_tensor = torch.arange(0, 10, 2)\n",
    "\n",
    "print(f\"\\nZeros:\\n{zeros}\")\n",
    "print(f\"Random:\\n{random}\")\n",
    "print(f\"Range: {range_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Element-wise addition:\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]])\n",
      "\n",
      "Matrix multiplication:\n",
      "Result shape: torch.Size([2, 2])\n",
      "tensor([[ 58.,  64.],\n",
      "        [139., 154.]])\n",
      "\n",
      "Broadcasting: torch.Size([2, 3]) + torch.Size([3]) = torch.Size([2, 3])\n",
      "tensor([[11, 22, 33],\n",
      "        [14, 25, 36]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor operations\n",
    "a = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)\n",
    "b = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)\n",
    "\n",
    "print(\"Element-wise addition:\")\n",
    "print(a + b)\n",
    "\n",
    "print(\"\\nMatrix multiplication:\")\n",
    "c = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "d = torch.tensor([[7, 8], [9, 10], [11, 12]], dtype=torch.float32)\n",
    "result = torch.mm(c, d)  # or c @ d\n",
    "print(f\"Result shape: {result.shape}\")\n",
    "print(result)\n",
    "\n",
    "# Broadcasting example\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "y = torch.tensor([10, 20, 30])\n",
    "print(f\"\\nBroadcasting: {x.shape} + {y.shape} = {(x + y).shape}\")\n",
    "print(x + y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Automatic Differentiation (Autograd)\n",
    "\n",
    "Autograd automatically computes gradients, which is essential for training neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x = 2.0\n",
      "y = 11.0\n",
      "dy/dx = 7.0 (expected: 7)\n",
      "\n",
      "Linear function: y = w*x + b\n",
      "dy/dw = 3.0 (should be x = 3.0)\n",
      "dy/db = 1.0 (should be 1)\n"
     ]
    }
   ],
   "source": [
    "# Basic autograd example\n",
    "x = torch.tensor([2.0], requires_grad=True)\n",
    "y = x**2 + 3*x + 1  # y = xÂ² + 3x + 1\n",
    "\n",
    "print(f\"x = {x.item()}\")\n",
    "print(f\"y = {y.item()}\")\n",
    "\n",
    "# Compute gradient: dy/dx = 2x + 3\n",
    "y.backward()\n",
    "print(f\"dy/dx = {x.grad.item()} (expected: {2*2 + 3})\")\n",
    "\n",
    "# Example with multiple variables\n",
    "w = torch.tensor([2.0], requires_grad=True)\n",
    "b = torch.tensor([1.0], requires_grad=True)\n",
    "x = torch.tensor([3.0])\n",
    "\n",
    "y = w * x + b\n",
    "y.backward()\n",
    "\n",
    "print(f\"\\nLinear function: y = w*x + b\")\n",
    "print(f\"dy/dw = {w.grad.item()} (should be x = {x.item()})\")\n",
    "print(f\"dy/db = {b.grad.item()} (should be 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding minimum of f(x) = (x-3)Â² + 1\n",
      "Iteration | x value | f(x) | gradient\n",
      "        0 |   0.000 | 10.000 |   -6.000\n",
      "        1 |   0.600 |  6.760 |   -4.800\n",
      "        2 |   1.080 |  4.686 |   -3.840\n",
      "        3 |   1.464 |  3.359 |   -3.072\n",
      "        4 |   1.771 |  2.510 |   -2.458\n",
      "        5 |   2.017 |  1.966 |   -1.966\n",
      "        6 |   2.214 |  1.618 |   -1.573\n",
      "        7 |   2.371 |  1.396 |   -1.258\n",
      "Final x: 2.497 (target: 3.000)\n"
     ]
    }
   ],
   "source": [
    "# Gradient descent demonstration\n",
    "def gradient_descent_demo():\n",
    "    # Find minimum of f(x) = (x - 3)Â² + 1\n",
    "    x = torch.tensor([0.0], requires_grad=True)\n",
    "    learning_rate = 0.1\n",
    "    \n",
    "    print(\"Finding minimum of f(x) = (x-3)Â² + 1\")\n",
    "    print(\"Iteration | x value | f(x) | gradient\")\n",
    "    \n",
    "    for i in range(8):\n",
    "        f_x = (x - 3)**2 + 1\n",
    "        \n",
    "        if x.grad is not None:\n",
    "            x.grad.zero_()\n",
    "        f_x.backward()\n",
    "        \n",
    "        print(f\"{i:9d} | {x.item():7.3f} | {f_x.item():6.3f} | {x.grad.item():8.3f}\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x -= learning_rate * x.grad\n",
    "    \n",
    "    print(f\"Final x: {x.item():.3f} (target: 3.000)\")\n",
    "\n",
    "gradient_descent_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Device Management\n",
    "\n",
    "PyTorch can run on CPU, CUDA GPU, or Apple's MPS for efficient computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "CPU tensor device: cpu\n",
      "Device tensor device: cpu\n",
      "Direct device tensor: cpu\n"
     ]
    }
   ],
   "source": [
    "# Device detection\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "        return torch.device(\"mps\")\n",
    "    else:\n",
    "        return torch.device(\"cpu\")\n",
    "\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Moving tensors to device\n",
    "cpu_tensor = torch.randn(3, 4)\n",
    "device_tensor = cpu_tensor.to(device)\n",
    "\n",
    "print(f\"CPU tensor device: {cpu_tensor.device}\")\n",
    "print(f\"Device tensor device: {device_tensor.device}\")\n",
    "\n",
    "# Create tensor directly on device\n",
    "direct_tensor = torch.randn(3, 4, device=device)\n",
    "print(f\"Direct device tensor: {direct_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building Neural Network Models\n",
    "\n",
    "Using `nn.Module` to create reusable model components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 2])\n",
      "Output shape: torch.Size([2, 1])\n",
      "Output:\n",
      "tensor([[-0.7027],\n",
      "        [-1.5789]], grad_fn=<AddmmBackward0>)\n",
      "linear.weight: torch.Size([1, 2])\n",
      "linear.bias: torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "class SimpleLinearModel(nn.Module):\n",
    "    \"\"\"Simple linear model: y = Wx + b\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, output_size):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "# Create and test model\n",
    "model = SimpleLinearModel(2, 1)\n",
    "test_input = torch.tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "output = model(test_input)\n",
    "\n",
    "print(f\"Input shape: {test_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output:\\n{output}\")\n",
    "\n",
    "# Examine parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Complete Example: Linear Regression\n",
    "\n",
    "A full training loop demonstrating the concepts we've learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: X=torch.Size([100, 1]), y=torch.Size([100, 1])\n",
      "True parameters: w=2.0, b=1.0\n",
      "Epoch   0, Loss: 2.3003\n",
      "Epoch  20, Loss: 1.0446\n",
      "Epoch  40, Loss: 0.4779\n",
      "Epoch  60, Loss: 0.2215\n",
      "Epoch  80, Loss: 0.1052\n",
      "\n",
      "Learned parameters: w=1.786, b=1.007\n",
      "True parameters:    w=2.000, b=1.000\n"
     ]
    }
   ],
   "source": [
    "# Generate synthetic data\n",
    "torch.manual_seed(42)\n",
    "n_samples = 100\n",
    "true_w, true_b = 2.0, 1.0\n",
    "\n",
    "X = torch.randn(n_samples, 1)\n",
    "y = true_w * X + true_b + 0.1 * torch.randn(n_samples, 1)\n",
    "\n",
    "print(f\"Data shape: X={X.shape}, y={y.shape}\")\n",
    "print(f\"True parameters: w={true_w}, b={true_b}\")\n",
    "\n",
    "# Create model\n",
    "model = SimpleLinearModel(1, 1).to(device)\n",
    "X, y = X.to(device), y.to(device)\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "epochs = 100\n",
    "\n",
    "# Training loop\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    # Forward pass\n",
    "    predictions = model(X)\n",
    "    loss = criterion(predictions, y)\n",
    "    \n",
    "    # Backward pass\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    losses.append(loss.item())\n",
    "    \n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch:3d}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Final parameters\n",
    "learned_w = model.linear.weight.item()\n",
    "learned_b = model.linear.bias.item()\n",
    "print(f\"\\nLearned parameters: w={learned_w:.3f}, b={learned_b:.3f}\")\n",
    "print(f\"True parameters:    w={true_w:.3f}, b={true_b:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot loss curve\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(losses)\n",
    "plt.title('Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot data and learned line\n",
    "plt.subplot(1, 2, 2)\n",
    "X_cpu, y_cpu = X.cpu(), y.cpu()\n",
    "plt.scatter(X_cpu.numpy(), y_cpu.numpy(), alpha=0.6, label='Data')\n",
    "\n",
    "# Plot true and learned lines\n",
    "x_line = torch.linspace(X_cpu.min(), X_cpu.max(), 100).unsqueeze(1)\n",
    "with torch.no_grad():\n",
    "    y_true = true_w * x_line + true_b\n",
    "    y_pred = model(x_line.to(device)).cpu()\n",
    "\n",
    "plt.plot(x_line, y_true, 'r-', label=f'True: y={true_w}x+{true_b}')\n",
    "plt.plot(x_line, y_pred, 'g--', label=f'Learned: y={learned_w:.2f}x+{learned_b:.2f}')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.title('Linear Regression Results')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ‰ Congratulations!\n",
    "\n",
    "You've learned the fundamental PyTorch concepts for chatbot development:\n",
    "\n",
    "âœ… **Tensors**: Multi-dimensional arrays for data representation  \n",
    "âœ… **Operations**: Mathematical operations and broadcasting  \n",
    "âœ… **Autograd**: Automatic differentiation for gradient computation  \n",
    "âœ… **Device Management**: CPU/GPU computation  \n",
    "âœ… **Neural Networks**: Building models with `nn.Module`  \n",
    "âœ… **Training Loop**: Complete learning process  \n",
    "\n",
    "## ðŸš€ Next Steps\n",
    "\n",
    "In the next notebook, we'll explore advanced tensor operations specifically for text processing, including:\n",
    "- Text tokenization with tensors\n",
    "- Batch processing techniques\n",
    "- Memory-efficient operations\n",
    "\n",
    "**Ready to continue?** Move on to [`02_tensor_operations.ipynb`](02_tensor_operations.ipynb)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
